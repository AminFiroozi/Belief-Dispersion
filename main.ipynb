{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec4f6c3",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff936e9",
   "metadata": {},
   "source": [
    "## LLM API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "86673a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_MODEL_NAME = 'gemini-2.0-flash'\n",
    "# GEMINI_MODEL_NAME = 'gemini-1.5-pro'\n",
    "MAX_API_RETRIES = 3\n",
    "API_INITIAL_DELAY = 5 # seconds\n",
    "REQUESTS_PER_MINUTE_LIMIT = 15 # For your reference or manual throttling logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e6db8",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2ef5f5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_SIZE_FOR_TESTING = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001645c6",
   "metadata": {},
   "source": [
    "# Imports and Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652be1f9",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "2fd5b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05000f",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "da3846f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk \n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from dotenv import load_dotenv\n",
    "from nltk.corpus import stopwords\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bea95d",
   "metadata": {},
   "source": [
    "## Download files and load env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a78830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1845559\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "dataset = load_dataset(\"ashraq/financial-news\")\n",
    "\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "df = df.head(SAMPLE_SIZE_FOR_TESTING)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88a0f3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01b9ad",
   "metadata": {},
   "source": [
    "## General overview on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9bec5362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of news articles: 10\n",
      "Number of unique stocks: 1\n",
      "Date range: 2020-05-05 00:00:00 to 2020-06-01 00:00:00\n",
      "Number of unique publishers: 2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of news articles: {len(df)}\")\n",
    "\n",
    "if 'stock' in df.columns:\n",
    "    print(f\"Number of unique stocks: {df['stock'].nunique()}\")\n",
    "else:\n",
    "    print(\"'stock' column not found for statistics.\")\n",
    "\n",
    "if 'date' in df.columns and not df['date'].dropna().empty:\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "elif 'date' in df.columns:\n",
    "    print(\"Date range: 'date' column is empty or all NaT after conversion.\")\n",
    "else:\n",
    "    print(\"'date' column not found for date range statistics.\")\n",
    "\n",
    "if 'publisher' in df.columns:\n",
    "    print(f\"Number of unique publishers: {df['publisher'].nunique()}\")\n",
    "else:\n",
    "    print(\"'publisher' column not found for statistics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a157f22",
   "metadata": {},
   "source": [
    "## Data type conversion for date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "310ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'date' column after conversion: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    print(f\"Data type of 'date' column after conversion: {df['date'].dtype}\")\n",
    "else:\n",
    "    print(\"'date' column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2ba19",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc0f9b",
   "metadata": {},
   "source": [
    "### Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "658f62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your original clean_text function (more aggressive cleaning)\n",
    "def clean_text_original(text):\n",
    "    text = str(text).lower()  # Ensure text is string and convert to lowercase\n",
    "    # Remove special characters and digits (keeps only letters and whitespace)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Suggested alternative clean_text function for LLM input\n",
    "# (keeps numbers and some essential punctuation, removes HTML)\n",
    "def clean_text_for_llm(text):\n",
    "    text = str(text) # Ensure text is string\n",
    "\n",
    "    # Remove HTML tags first (if any)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Decode common HTML entities (simple version for &amp; &lt; &gt;)\n",
    "    # For more comprehensive decoding, consider the 'html' library:\n",
    "    # import html\n",
    "    # text = html.unescape(text)\n",
    "    text = text.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Keep letters, numbers, and a basic set of punctuation.\n",
    "    # This regex keeps: a-z, 0-9, whitespace, and . , ' - $ % ! ?\n",
    "    # Adjust the punctuation list r'[^a-zA-Z0-9\\s\\.,\\'\\-\\$\\%\\!\\?]' as needed.\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.,\\'\\-\\$\\%\\!\\?]', '', text)\n",
    "\n",
    "    # Normalize whitespace (remove extra spaces, trim leading/trailing)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cfacf",
   "metadata": {},
   "source": [
    "### Apply declared functions on the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "b0e7779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'headline' in df.columns:\n",
    "    # Apply original aggressive cleaning\n",
    "    df['clean_headline_original'] = df['headline'].apply(clean_text_original)\n",
    "\n",
    "    # Apply LLM-friendly cleaning\n",
    "    df['llm_ready_headline'] = df['headline'].apply(clean_text_for_llm)\n",
    "else:\n",
    "    print(\"'headline' column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904c15c",
   "metadata": {},
   "source": [
    "### Tokenizing headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "772abcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'clean_headline_original' in df.columns:\n",
    "    # Note: For LLMs, you typically feed the 'llm_ready_headline' string directly.\n",
    "    # This tokenization is shown as per your original script.\n",
    "    df['tokens_original'] = df['clean_headline_original'].apply(word_tokenize)\n",
    "else:\n",
    "    print(\"'clean_headline_original' column not found for tokenization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325a778",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "af574d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'tokens_original' in df.columns:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['tokens_no_stopwords'] = df['tokens_original'].apply(lambda token_list: [word for word in token_list if word not in stop_words])\n",
    "else:\n",
    "    print(\"'tokens_original' column not found for stopword removal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe25d65",
   "metadata": {},
   "source": [
    "## Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0430f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'url' column dropped successfully.\n",
      "\n",
      "DataFrame columns after attempting to drop 'url':\n",
      "['headline', 'publisher', 'date', 'stock', 'clean_headline_original', 'llm_ready_headline', 'tokens_original', 'tokens_no_stopwords']\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['url']\n",
    "if columns_to_drop[0] in df.columns:\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    print(f\"'{columns_to_drop[0]}' column dropped successfully.\")\n",
    "else:\n",
    "    print(f\"'{columns_to_drop[0]}' column not found or already dropped.\")\n",
    "\n",
    "print(\"\\nDataFrame columns after attempting to drop 'url':\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d66b49fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>clean_headline_original</th>\n",
       "      <th>llm_ready_headline</th>\n",
       "      <th>tokens_original</th>\n",
       "      <th>tokens_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5â€¦â€¦...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>A</td>\n",
       "      <td>agilent technologies announces pricing of mill...</td>\n",
       "      <td>agilent technologies announces pricing of $5 m...</td>\n",
       "      <td>[agilent, technologies, announces, pricing, of...</td>\n",
       "      <td>[agilent, technologies, announces, pricing, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>A</td>\n",
       "      <td>agilent a gears up for q earnings whats in the...</td>\n",
       "      <td>agilent a gears up for q2 earnings what's in t...</td>\n",
       "      <td>[agilent, a, gears, up, for, q, earnings, what...</td>\n",
       "      <td>[agilent, gears, q, earnings, whats, cards]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>jp morgan asset management announces liquidati...</td>\n",
       "      <td>j.p. morgan asset management announces liquida...</td>\n",
       "      <td>[jp, morgan, asset, management, announces, liq...</td>\n",
       "      <td>[jp, morgan, asset, management, announces, liq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>pershing square capital management lp buys agi...</td>\n",
       "      <td>pershing square capital management, l.p. buys ...</td>\n",
       "      <td>[pershing, square, capital, management, lp, bu...</td>\n",
       "      <td>[pershing, square, capital, management, lp, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>A</td>\n",
       "      <td>agilent awards trilogy sciences with a golden ...</td>\n",
       "      <td>agilent awards trilogy sciences with a golden ...</td>\n",
       "      <td>[agilent, awards, trilogy, sciences, with, a, ...</td>\n",
       "      <td>[agilent, awards, trilogy, sciences, golden, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  publisher       date  \\\n",
       "0  Agilent Technologies Announces Pricing of $5â€¦â€¦...  GuruFocus 2020-06-01   \n",
       "1  Agilent (A) Gears Up for Q2 Earnings: What's i...      Zacks 2020-05-18   \n",
       "2  J.P. Morgan Asset Management Announces Liquida...  GuruFocus 2020-05-15   \n",
       "3  Pershing Square Capital Management, L.P. Buys ...  GuruFocus 2020-05-15   \n",
       "4  Agilent Awards Trilogy Sciences with a Golden ...  GuruFocus 2020-05-12   \n",
       "\n",
       "  stock                            clean_headline_original  \\\n",
       "0     A  agilent technologies announces pricing of mill...   \n",
       "1     A  agilent a gears up for q earnings whats in the...   \n",
       "2     A  jp morgan asset management announces liquidati...   \n",
       "3     A  pershing square capital management lp buys agi...   \n",
       "4     A  agilent awards trilogy sciences with a golden ...   \n",
       "\n",
       "                                  llm_ready_headline  \\\n",
       "0  agilent technologies announces pricing of $5 m...   \n",
       "1  agilent a gears up for q2 earnings what's in t...   \n",
       "2  j.p. morgan asset management announces liquida...   \n",
       "3  pershing square capital management, l.p. buys ...   \n",
       "4  agilent awards trilogy sciences with a golden ...   \n",
       "\n",
       "                                     tokens_original  \\\n",
       "0  [agilent, technologies, announces, pricing, of...   \n",
       "1  [agilent, a, gears, up, for, q, earnings, what...   \n",
       "2  [jp, morgan, asset, management, announces, liq...   \n",
       "3  [pershing, square, capital, management, lp, bu...   \n",
       "4  [agilent, awards, trilogy, sciences, with, a, ...   \n",
       "\n",
       "                                 tokens_no_stopwords  \n",
       "0  [agilent, technologies, announces, pricing, mi...  \n",
       "1        [agilent, gears, q, earnings, whats, cards]  \n",
       "2  [jp, morgan, asset, management, announces, liq...  \n",
       "3  [pershing, square, capital, management, lp, bu...  \n",
       "4  [agilent, awards, trilogy, sciences, golden, t...  "
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fc8c8d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34db469",
   "metadata": {},
   "source": [
    "## Configure API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "e3a5c050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API configured.\n",
      "Using Gemini model: models/gemini-2.0-flash\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"API Key not found. Please set it.\")\n",
    "else:\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        print(\"Gemini API configured.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error configuring Gemini API: {e}\")\n",
    "\n",
    "# --- Initialize the Model ---\n",
    "# (Ensure API key was configured successfully before this)\n",
    "model = None\n",
    "if api_key: # Check if API key is available\n",
    "     try:\n",
    "         model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "         print(f\"Using Gemini model: {model.model_name}\")\n",
    "     except Exception as e:\n",
    "         print(f\"Error initializing Gemini model: {e}\")\n",
    "         print(\"Please ensure your API key is valid, properly configured, and the model name is correct.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80206d05",
   "metadata": {},
   "source": [
    "## Define Sentiment Analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "73051876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score_gemini(headline_text, stock_symbol, max_retries=3, initial_delay=5):\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a given headline using the Gemini API\n",
    "    and returns a numerical score between -1.0 and 1.0.\n",
    "\n",
    "    Args:\n",
    "        headline_text (str): The news headline to analyze.\n",
    "        max_retries (int): Maximum number of retries for API calls.\n",
    "        initial_delay (int): Initial delay in seconds for retries.\n",
    "\n",
    "    Returns:\n",
    "        float or None: The sentiment score, or None if analysis fails or score is invalid.\n",
    "    \"\"\"\n",
    "    global model # Access the globally initialized model\n",
    "    if not model:\n",
    "        print(\"ðŸ”´ Error: Gemini model not initialized. Cannot perform sentiment analysis.\")\n",
    "        return None\n",
    "    if not headline_text or not isinstance(headline_text, str) or headline_text.strip() == \"\":\n",
    "        print(f\"ðŸŸ¡ Invalid Input: Headline is empty or not a string. Received: {headline_text}\")\n",
    "        return None\n",
    "\n",
    "    # Crafting a prompt for a numerical sentiment score\n",
    "    prompt = f\"\"\"You are a financial sentiment analysis assistant.\n",
    "\n",
    "Given a news headline about a stock, analyze its sentiment with respect to the mentioned stock symbol and return a sentiment score between -1 and 1:\n",
    "\n",
    "1 means extremely positive and bullish.\n",
    "\n",
    "-1 means extremely negative and bearish.\n",
    "\n",
    "Values in between indicate mixed or neutral sentiment, with 0 being completely neutral.\n",
    "\n",
    "Format your response exactly like this:\n",
    "<a number between -1 and 1>\n",
    "\n",
    "Example Input:\n",
    "Agilent (A) Gears Up for Q2 Earnings: What's in the Cards?\n",
    "\n",
    "stock symbol: {stock_symbol}\n",
    "Now analyze this headline:\n",
    "{headline_text}\n",
    "\"\"\"\n",
    "\n",
    "    num_retries = 0\n",
    "    delay = initial_delay\n",
    "    while num_retries <= max_retries:\n",
    "        try:\n",
    "            generation_config = genai.types.GenerationConfig(\n",
    "                candidate_count=1,\n",
    "                temperature=0.1 # Lower temperature for more deterministic, less \"creative\" scoring\n",
    "            )\n",
    "            response = model.generate_content(prompt, generation_config=generation_config)\n",
    "\n",
    "            if response.candidates and response.candidates[0].content.parts:\n",
    "                score_text = response.candidates[0].content.parts[0].text.strip()\n",
    "                try:\n",
    "                    score = float(score_text)\n",
    "                    if -1.0 <= score <= 1.0:\n",
    "                        return score  # Successfully parsed and validated score\n",
    "                    else:\n",
    "                        print(f\"ðŸŸ¡ Warning: Score '{score}' from API is out of range [-1.0, 1.0] for headline: '{headline_text}'. Returning None.\")\n",
    "                        return None # Score is out of the expected range\n",
    "                except ValueError:\n",
    "                    print(f\"ðŸŸ¡ Warning: Could not convert API response '{score_text}' to a float score for headline: '{headline_text}'. Returning None.\")\n",
    "                    return None # API did not return a parseable number\n",
    "            else:\n",
    "                # Handle blocked responses or other issues\n",
    "                if response.prompt_feedback and response.prompt_feedback.block_reason:\n",
    "                    print(f\"ðŸŸ¡ Warning: Prompt blocked for headline '{headline_text}'. Reason: {response.prompt_feedback.block_reason.name}. No retry.\")\n",
    "                    return None # Or a specific value like -999 to indicate blockage\n",
    "                print(f\"ðŸŸ¡ Warning: No valid candidate or content part in API response for headline: '{headline_text}'.\")\n",
    "                return None\n",
    "\n",
    "        except Exception as e: # Catching a broader set of exceptions\n",
    "            # Check if the error message or type indicates a rate limit (429 error)\n",
    "            if \"429\" in str(e) or \"exceeded your current quota\" in str(e).lower() or \"resource has been exhausted\" in str(e).lower():\n",
    "                if num_retries < max_retries:\n",
    "                    print(f\"ðŸŸ¡ Rate limit hit for headline '{headline_text}'. Retrying in {delay}s... (Attempt {num_retries+1}/{max_retries})\")\n",
    "                    time.sleep(delay)\n",
    "                    num_retries += 1\n",
    "                    delay *= 2 # Exponential backoff\n",
    "                else:\n",
    "                    print(f\"ðŸ”´ Error: Max retries ({max_retries}) exceeded for rate limit on headline '{headline_text}'.\")\n",
    "                    return None # Max retries exceeded\n",
    "            else:\n",
    "                # For other types of errors, don't retry\n",
    "                print(f\"ðŸ”´ An unexpected API error occurred for headline '{headline_text}': {e}\")\n",
    "                return None\n",
    "    \n",
    "    print(f\"ðŸ”´ Error: Failed to get sentiment score for '{headline_text}' after all retries or due to an earlier non-retryable error.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f198c18",
   "metadata": {},
   "source": [
    "## Apply Sentiment Analysis functions on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b918c753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10 headlines...\n",
      "Processing headline (1/10): agilent technologies announces pricing of $5 million of senior notes...\n",
      "Processing headline (2/10): agilent a gears up for q2 earnings what's in the cards?...\n",
      "Processing headline (3/10): j.p. morgan asset management announces liquidation of six exchange-tra...\n",
      "Processing headline (4/10): pershing square capital management, l.p. buys agilent technologies inc...\n",
      "Processing headline (5/10): agilent awards trilogy sciences with a golden ticket at labcentral...\n",
      "Processing headline (6/10): agilent technologies inc a ceo and president michael r. mcmullen sold ...\n",
      "Processing headline (7/10): ' stocks growing their earnings fast...\n",
      "Processing headline (8/10): cypress asset management inc buys verizon communications inc, united p...\n",
      "Processing headline (9/10): hendley co inc buys american electric power co inc, agilent technologi...\n",
      "Processing headline (10/10): teacher retirement system of texas buys hologic inc, vanguard total st...\n",
      "\n",
      "DataFrame with Sentiment Analysis results:\n",
      "                                  llm_ready_headline  gemini_sentiment\n",
      "0  agilent technologies announces pricing of $5 m...              -0.2\n",
      "1  agilent a gears up for q2 earnings what's in t...               0.2\n",
      "2  j.p. morgan asset management announces liquida...              -0.3\n",
      "3  pershing square capital management, l.p. buys ...               0.3\n",
      "4  agilent awards trilogy sciences with a golden ...               0.2\n"
     ]
    }
   ],
   "source": [
    "if 'llm_ready_headline' in df.columns and model: # Proceed only if df and model are ready\n",
    "    print(f\"Processing {len(df)} headlines...\")\n",
    "\n",
    "    # df['gemini_sentiment'] = df['llm_ready_headline'].apply(get_sentiment_gemini)\n",
    "    \n",
    "    sentiments = []\n",
    "    for index, row in df.iterrows(): # Or however you are iterating\n",
    "        headline = row['llm_ready_headline']\n",
    "        stock_symbol = row['stock']\n",
    "        print(f\"Processing headline ({index+1}/{len(df)}): {headline[:70]}...\")\n",
    "        sentiment = get_sentiment_score_gemini(headline, stock_symbol)\n",
    "        sentiments.append(sentiment)\n",
    "        # Add a delay to stay within rate limits\n",
    "        time.sleep(4) # Wait for 4 seconds before the next request\n",
    "\n",
    "    df['gemini_sentiment'] = sentiments\n",
    "\n",
    "    print(\"\\nDataFrame with Sentiment Analysis results:\")\n",
    "    print(df[['llm_ready_headline', 'gemini_sentiment']].head())\n",
    "elif not model:\n",
    "    print(\"Cannot apply sentiment analysis because the Gemini model is not initialized.\")\n",
    "else:\n",
    "    print(\"DataFrame 'df' or 'llm_ready_headline' column not found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
