{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001645c6",
   "metadata": {},
   "source": [
    "# Imports and Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da3846f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re # For regular expressions\n",
    "import nltk # Natural Language Toolkit\n",
    "\n",
    "# Download required NLTK data (if not already downloaded)\n",
    "# Using quiet=True to avoid verbose output if already present\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Optional: Configure pandas display options if needed\n",
    "# pd.set_option('display.max_colwidth', 200) # To see more of the headline text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6603f835",
   "metadata": {},
   "source": [
    "# Get the Dataset ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6fe1858c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"ashraq/financial-news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf62e567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['headline', 'url', 'publisher', 'date', 'stock'],\n",
       "        num_rows: 1845559\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "799a96ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>http://www.gurufocus.com/news/1153187/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>http://www.zacks.com/stock/news/931205/agilent...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138923/jp-morga...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138704/pershing...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>http://www.gurufocus.com/news/1134012/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Agilent Technologies Announces Pricing of $5……...   \n",
       "1  Agilent (A) Gears Up for Q2 Earnings: What's i...   \n",
       "2  J.P. Morgan Asset Management Announces Liquida...   \n",
       "3  Pershing Square Capital Management, L.P. Buys ...   \n",
       "4  Agilent Awards Trilogy Sciences with a Golden ...   \n",
       "\n",
       "                                                 url  publisher  \\\n",
       "0  http://www.gurufocus.com/news/1153187/agilent-...  GuruFocus   \n",
       "1  http://www.zacks.com/stock/news/931205/agilent...      Zacks   \n",
       "2  http://www.gurufocus.com/news/1138923/jp-morga...  GuruFocus   \n",
       "3  http://www.gurufocus.com/news/1138704/pershing...  GuruFocus   \n",
       "4  http://www.gurufocus.com/news/1134012/agilent-...  GuruFocus   \n",
       "\n",
       "                  date stock  \n",
       "0  2020-06-01 00:00:00     A  \n",
       "1  2020-05-18 00:00:00     A  \n",
       "2  2020-05-15 00:00:00     A  \n",
       "3  2020-05-15 00:00:00     A  \n",
       "4  2020-05-12 00:00:00     A  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the train split to a DataFrame\n",
    "df = pd.DataFrame(dataset['train'][:100])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f88a0f3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01b9ad",
   "metadata": {},
   "source": [
    "## General overview on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bec5362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of news articles: 100\n",
      "Number of unique stocks: 1\n",
      "Date range: 2019-11-07 00:00:00 to 2020-06-01 00:00:00\n",
      "Number of unique publishers: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of news articles: {len(df)}\")\n",
    "\n",
    "if 'stock' in df.columns:\n",
    "    print(f\"Number of unique stocks: {df['stock'].nunique()}\")\n",
    "else:\n",
    "    print(\"'stock' column not found for statistics.\")\n",
    "\n",
    "if 'date' in df.columns and not df['date'].dropna().empty:\n",
    "    print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "elif 'date' in df.columns:\n",
    "    print(\"Date range: 'date' column is empty or all NaT after conversion.\")\n",
    "else:\n",
    "    print(\"'date' column not found for date range statistics.\")\n",
    "\n",
    "if 'publisher' in df.columns:\n",
    "    print(f\"Number of unique publishers: {df['publisher'].nunique()}\")\n",
    "else:\n",
    "    print(\"'publisher' column not found for statistics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a157f22",
   "metadata": {},
   "source": [
    "## Data type conversion for date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "310ddf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type of 'date' column after conversion: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    print(f\"Data type of 'date' column after conversion: {df['date'].dtype}\")\n",
    "else:\n",
    "    print(\"'date' column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2ba19",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffc0f9b",
   "metadata": {},
   "source": [
    "### Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "658f62ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your original clean_text function (more aggressive cleaning)\n",
    "def clean_text_original(text):\n",
    "    text = str(text).lower()  # Ensure text is string and convert to lowercase\n",
    "    # Remove special characters and digits (keeps only letters and whitespace)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Suggested alternative clean_text function for LLM input\n",
    "# (keeps numbers and some essential punctuation, removes HTML)\n",
    "def clean_text_for_llm(text):\n",
    "    text = str(text) # Ensure text is string\n",
    "\n",
    "    # Remove HTML tags first (if any)\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    # Decode common HTML entities (simple version for &amp; &lt; &gt;)\n",
    "    # For more comprehensive decoding, consider the 'html' library:\n",
    "    # import html\n",
    "    # text = html.unescape(text)\n",
    "    text = text.replace('&amp;', '&').replace('&lt;', '<').replace('&gt;', '>')\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Keep letters, numbers, and a basic set of punctuation.\n",
    "    # This regex keeps: a-z, 0-9, whitespace, and . , ' - $ % ! ?\n",
    "    # Adjust the punctuation list r'[^a-zA-Z0-9\\s\\.,\\'\\-\\$\\%\\!\\?]' as needed.\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\.,\\'\\-\\$\\%\\!\\?]', '', text)\n",
    "\n",
    "    # Normalize whitespace (remove extra spaces, trim leading/trailing)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675cfacf",
   "metadata": {},
   "source": [
    "### Apply declared functions on the headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0e7779b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'headline' in df.columns:\n",
    "    # Apply original aggressive cleaning\n",
    "    df['clean_headline_original'] = df['headline'].apply(clean_text_original)\n",
    "\n",
    "    # Apply LLM-friendly cleaning\n",
    "    df['llm_ready_headline'] = df['headline'].apply(clean_text_for_llm)\n",
    "else:\n",
    "    print(\"'headline' column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f904c15c",
   "metadata": {},
   "source": [
    "### Tokenizing headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "772abcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'clean_headline_original' in df.columns:\n",
    "    # Note: For LLMs, you typically feed the 'llm_ready_headline' string directly.\n",
    "    # This tokenization is shown as per your original script.\n",
    "    df['tokens_original'] = df['clean_headline_original'].apply(word_tokenize)\n",
    "else:\n",
    "    print(\"'clean_headline_original' column not found for tokenization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5325a778",
   "metadata": {},
   "source": [
    "### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "af574d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'tokens_original' in df.columns:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df['tokens_no_stopwords'] = df['tokens_original'].apply(lambda token_list: [word for word in token_list if word not in stop_words])\n",
    "else:\n",
    "    print(\"'tokens_original' column not found for stopword removal.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe25d65",
   "metadata": {},
   "source": [
    "## Dropping unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430f8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6: Dropping 'url' column\n",
      "'url' column dropped successfully.\n",
      "\n",
      "DataFrame columns after attempting to drop 'url':\n",
      "['headline', 'publisher', 'date', 'stock', 'clean_headline_original', 'llm_ready_headline', 'tokens_original', 'tokens_no_stopwords']\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['url']\n",
    "if columns_to_drop[0] in df.columns:\n",
    "    df = df.drop(columns=columns_to_drop)\n",
    "    print(f\"'{columns_to_drop[0]}' column dropped successfully.\")\n",
    "else:\n",
    "    print(f\"'{columns_to_drop[0]}' column not found or already dropped.\")\n",
    "\n",
    "print(\"\\nDataFrame columns after attempting to drop 'url':\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d66b49fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "      <th>clean_headline_original</th>\n",
       "      <th>llm_ready_headline</th>\n",
       "      <th>tokens_original</th>\n",
       "      <th>tokens_no_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agilent Technologies Announces Pricing of $5……...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>A</td>\n",
       "      <td>agilent technologies announces pricing of mill...</td>\n",
       "      <td>agilent technologies announces pricing of $5 m...</td>\n",
       "      <td>[agilent, technologies, announces, pricing, of...</td>\n",
       "      <td>[agilent, technologies, announces, pricing, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agilent (A) Gears Up for Q2 Earnings: What's i...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18</td>\n",
       "      <td>A</td>\n",
       "      <td>agilent a gears up for q earnings whats in the...</td>\n",
       "      <td>agilent a gears up for q2 earnings what's in t...</td>\n",
       "      <td>[agilent, a, gears, up, for, q, earnings, what...</td>\n",
       "      <td>[agilent, gears, q, earnings, whats, cards]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.P. Morgan Asset Management Announces Liquida...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>jp morgan asset management announces liquidati...</td>\n",
       "      <td>j.p. morgan asset management announces liquida...</td>\n",
       "      <td>[jp, morgan, asset, management, announces, liq...</td>\n",
       "      <td>[jp, morgan, asset, management, announces, liq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pershing Square Capital Management, L.P. Buys ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>A</td>\n",
       "      <td>pershing square capital management lp buys agi...</td>\n",
       "      <td>pershing square capital management, l.p. buys ...</td>\n",
       "      <td>[pershing, square, capital, management, lp, bu...</td>\n",
       "      <td>[pershing, square, capital, management, lp, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Agilent Awards Trilogy Sciences with a Golden ...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12</td>\n",
       "      <td>A</td>\n",
       "      <td>agilent awards trilogy sciences with a golden ...</td>\n",
       "      <td>agilent awards trilogy sciences with a golden ...</td>\n",
       "      <td>[agilent, awards, trilogy, sciences, with, a, ...</td>\n",
       "      <td>[agilent, awards, trilogy, sciences, golden, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  publisher       date  \\\n",
       "0  Agilent Technologies Announces Pricing of $5……...  GuruFocus 2020-06-01   \n",
       "1  Agilent (A) Gears Up for Q2 Earnings: What's i...      Zacks 2020-05-18   \n",
       "2  J.P. Morgan Asset Management Announces Liquida...  GuruFocus 2020-05-15   \n",
       "3  Pershing Square Capital Management, L.P. Buys ...  GuruFocus 2020-05-15   \n",
       "4  Agilent Awards Trilogy Sciences with a Golden ...  GuruFocus 2020-05-12   \n",
       "\n",
       "  stock                            clean_headline_original  \\\n",
       "0     A  agilent technologies announces pricing of mill...   \n",
       "1     A  agilent a gears up for q earnings whats in the...   \n",
       "2     A  jp morgan asset management announces liquidati...   \n",
       "3     A  pershing square capital management lp buys agi...   \n",
       "4     A  agilent awards trilogy sciences with a golden ...   \n",
       "\n",
       "                                  llm_ready_headline  \\\n",
       "0  agilent technologies announces pricing of $5 m...   \n",
       "1  agilent a gears up for q2 earnings what's in t...   \n",
       "2  j.p. morgan asset management announces liquida...   \n",
       "3  pershing square capital management, l.p. buys ...   \n",
       "4  agilent awards trilogy sciences with a golden ...   \n",
       "\n",
       "                                     tokens_original  \\\n",
       "0  [agilent, technologies, announces, pricing, of...   \n",
       "1  [agilent, a, gears, up, for, q, earnings, what...   \n",
       "2  [jp, morgan, asset, management, announces, liq...   \n",
       "3  [pershing, square, capital, management, lp, bu...   \n",
       "4  [agilent, awards, trilogy, sciences, with, a, ...   \n",
       "\n",
       "                                 tokens_no_stopwords  \n",
       "0  [agilent, technologies, announces, pricing, mi...  \n",
       "1        [agilent, gears, q, earnings, whats, cards]  \n",
       "2  [jp, morgan, asset, management, announces, liq...  \n",
       "3  [pershing, square, capital, management, lp, bu...  \n",
       "4  [agilent, awards, trilogy, sciences, golden, t...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
